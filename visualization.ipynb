{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import glob\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from models.dataset import SurfaceOptionsDataModule, SURFACE_FEATURE_COLUMNS\n",
    "from models.module import SurfaceTransformerOptionModule\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ],
   "id": "4d8e7bbf302391ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- Constants ---\n",
    "CHECKPOINT_PATH = \"./checkpoints/run_20260226_162446_020301/epoch=399-step=24000.ckpt\"\n",
    "DATA_DIR = \"./data/108105\"\n",
    "\n",
    "DATES_PER_BATCH = 8\n",
    "CONTEXT_SIZE = 64\n",
    "QUERY_SIZE = 64\n",
    "BATCH_SIZE_DATES = 8\n",
    "\n",
    "SELECTED_DATE = \"2025-08-29\"  # e.g. \"2025-08-29\"; None -> latest available date\n",
    "CP_FLAG = \"C\"\n",
    "GRID_SIZE = 30\n",
    "SEED = 42\n",
    "\n",
    "DIVIDEND_YIELD_FALLBACK = 0.0\n",
    "RATE_FALLBACK = 0.04\n"
   ],
   "id": "cef66c0ea453f722",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "def choose_device():\n    if torch.backends.mps.is_available():\n        return \"mps\"\n    if torch.cuda.is_available():\n        return \"cuda\"\n    return \"cpu\"\n\n\ndef resolve_checkpoint_path(checkpoint_path):\n    if checkpoint_path:\n        candidate = Path(checkpoint_path)\n        if not candidate.exists():\n            raise FileNotFoundError(f\"Checkpoint does not exist: {candidate}\")\n        return str(candidate)\n\n    # Prefer last.ckpt from latest run directory; fallback to latest .ckpt by mtime.\n    run_dirs = sorted(Path(\"./checkpoints\").glob(\"run_*\"), key=lambda p: p.stat().st_mtime)\n    for run_dir in reversed(run_dirs):\n        last_ckpt = run_dir / \"last.ckpt\"\n        if last_ckpt.exists():\n            return str(last_ckpt)\n\n    all_ckpts = sorted(Path(\"./checkpoints\").glob(\"run_*/*.ckpt\"), key=lambda p: p.stat().st_mtime)\n    if not all_ckpts:\n        raise FileNotFoundError(\n            \"No checkpoint found under ./checkpoints. Set CHECKPOINT_PATH explicitly.\"\n        )\n    return str(all_ckpts[-1])\n\n\ndef _median_or_fallback(frame, column_name, fallback):\n    value = frame.select(pl.col(column_name).median()).item()\n    if value is None or not np.isfinite(value):\n        return float(fallback)\n    return float(value)\n\n\ndef load_preprocessed_surface_frame(data_dir, cp_flag=\"C\"):\n    files = sorted(glob.glob(f\"{data_dir}/*.csv\"))\n    if not files:\n        raise ValueError(f\"No csv files found in {data_dir}.\")\n\n    frame = pl.concat(\n        [pl.read_csv(path, try_parse_dates=True) for path in files],\n        how=\"vertical_relaxed\",\n    )\n\n    date_dtype = frame.schema.get(\"date\")\n    if date_dtype == pl.String:\n        frame = frame.with_columns(pl.col(\"date\").str.to_datetime(strict=False).alias(\"date\"))\n        date_dtype = frame.schema.get(\"date\")\n\n    if date_dtype == pl.Datetime:\n        frame = frame.with_columns(pl.col(\"date\").dt.date().alias(\"date\"))\n    elif date_dtype != pl.Date:\n        frame = frame.with_columns(pl.col(\"date\").cast(pl.Date).alias(\"date\"))\n\n    if \"cp_flag\" in frame.columns and cp_flag is not None:\n        frame = frame.filter(pl.col(\"cp_flag\") == cp_flag)\n\n    k_safe = pl.when(pl.col(\"K\") > 1e-8).then(pl.col(\"K\")).otherwise(1e-8)\n    frame = (\n        frame.sort(\"date\")\n        .filter((pl.col(\"T\") < 365) & (pl.col(\"T\") > 14))\n        .with_columns(\n            M=pl.col(\"S\") / k_safe,\n            vix=pl.col(\"vix\") / 100.0,\n            T=pl.col(\"T\") / 365.0,\n        )\n        .filter((pl.col(\"M\") >= 0.5) & (pl.col(\"M\") <= 1.15))\n    )\n\n    finite_cols = [\"Price\", \"S\", \"K\", \"T\", \"vix\", \"dividend_yield\", \"rate\"]\n    frame = frame.with_columns(\n        [\n            pl.when(pl.col(col).is_finite()).then(pl.col(col)).otherwise(None).alias(col)\n            for col in finite_cols\n        ]\n    )\n\n    base_required = [\"date\", \"Price\", \"S\", \"K\", \"T\", \"vix\", \"dividend_yield\", \"rate\"]\n    frame = frame.drop_nulls(subset=base_required)\n\n    frame = frame.with_columns(\n        dividend_yield=pl.col(\"dividend_yield\").fill_null(DIVIDEND_YIELD_FALLBACK),\n        rate=pl.col(\"rate\").fill_null(RATE_FALLBACK),\n    )\n\n    frame = frame.drop_nulls(subset=SURFACE_FEATURE_COLUMNS + [\"Price\", \"date\"]).sort(\"date\")\n    return frame\n\n\ndef build_context_and_query_for_date(daily_df, context_size, grid_size, seed=42):\n    if daily_df.is_empty():\n        raise ValueError(\"daily_df is empty\")\n\n    rng = np.random.default_rng(seed)\n\n    feature_values = daily_df.select(SURFACE_FEATURE_COLUMNS).to_numpy().astype(np.float32)\n    price_values = daily_df.select(\"Price\").to_numpy().astype(np.float32)\n\n    # Context sampled from actual rows for the date.\n    replace = daily_df.height < context_size\n    context_idx = rng.choice(daily_df.height, size=context_size, replace=replace)\n\n    context_x = torch.tensor(feature_values[context_idx], dtype=torch.float32).unsqueeze(0)\n    context_y = torch.tensor(price_values[context_idx], dtype=torch.float32).unsqueeze(0)\n    context_mask = torch.ones((1, context_size), dtype=torch.bool)\n\n    # Query grid for surface plotting.\n    s_fixed = _median_or_fallback(daily_df, \"S\", np.nan)\n    if not np.isfinite(s_fixed) or s_fixed <= 0:\n        raise ValueError(\"Invalid S median for selected date.\")\n\n    t_min_raw = daily_df.select(pl.col(\"T\").min()).item()\n    t_max_raw = daily_df.select(pl.col(\"T\").max()).item()\n    t_min = float(t_min_raw) if t_min_raw is not None else np.nan\n    t_max = float(t_max_raw) if t_max_raw is not None else np.nan\n\n    t_min = max(t_min, 15.0 / 365.0) if np.isfinite(t_min) else 15.0 / 365.0\n    t_max = min(t_max, 365.0 / 365.0) if np.isfinite(t_max) else 365.0 / 365.0\n    if t_max <= t_min:\n        t_min, t_max = 15.0 / 365.0, 365.0 / 365.0\n\n    moneyness_values = np.linspace(0.5, 1.15, grid_size)\n    t_values = np.linspace(t_min, t_max, grid_size)\n    m_grid, t_grid = np.meshgrid(moneyness_values, t_values)\n    k_grid = s_fixed / np.clip(m_grid, 1e-8, None)\n\n    q_len = m_grid.size\n    query_df = pl.DataFrame(\n        {\n            \"S\": np.full(q_len, s_fixed, dtype=np.float32),\n            \"K\": k_grid.reshape(-1).astype(np.float32),\n            \"T\": t_grid.reshape(-1).astype(np.float32),\n            \"vix\": np.full(q_len, _median_or_fallback(daily_df, \"vix\", 0.20), dtype=np.float32),\n            \"dividend_yield\": np.full(\n                q_len,\n                _median_or_fallback(daily_df, \"dividend_yield\", DIVIDEND_YIELD_FALLBACK),\n                dtype=np.float32,\n            ),\n            \"rate\": np.full(q_len, _median_or_fallback(daily_df, \"rate\", RATE_FALLBACK), dtype=np.float32),\n        }\n    )\n\n    query_x = torch.tensor(\n        query_df.select(SURFACE_FEATURE_COLUMNS).to_numpy().astype(np.float32),\n        dtype=torch.float32,\n    ).unsqueeze(0)\n\n    return query_x, context_x, context_y, context_mask, m_grid, t_grid, k_grid\n\n\ndef plot_surface(z_grid, x_grid, y_grid, title, x_title, y_title, z_title):\n    fig = go.Figure(\n        data=[\n            go.Surface(\n                z=z_grid,\n                x=x_grid,\n                y=y_grid,\n                colorscale=\"Viridis\",\n                colorbar=dict(title=z_title),\n            )\n        ]\n    )\n    fig.update_layout(\n        title=title,\n        scene=dict(\n            xaxis_title=x_title,\n            yaxis_title=y_title,\n            zaxis_title=z_title,\n        ),\n        template=\"plotly_white\",\n        width=1000,\n        height=650,\n    )\n    fig.show()\n",
   "id": "50587fb7eb2299f5",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"Loading data module...\")\n",
    "data_module = SurfaceOptionsDataModule(\n",
    "    DATA_DIR,\n",
    "    context_size=CONTEXT_SIZE,\n",
    "    query_size=QUERY_SIZE,\n",
    "    batch_size_dates=BATCH_SIZE_DATES,\n",
    "    num_workers=4,\n",
    "    seed=SEED,\n",
    ")\n",
    "data_module.setup(\"fit\")\n",
    "\n",
    "ckpt_path = resolve_checkpoint_path(CHECKPOINT_PATH)\n",
    "print(f\"Loading model from {ckpt_path}...\")\n",
    "model = SurfaceTransformerOptionModule.load_from_checkpoint(ckpt_path)\n",
    "model.eval()\n",
    "\n",
    "device = choose_device()\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"raw_input_dim={model.hparams.raw_input_dim}, context_size={model.hparams.context_size}, query_size={model.hparams.query_size}\")\n",
    "if int(model.hparams.raw_input_dim) != len(SURFACE_FEATURE_COLUMNS):\n",
    "    raise ValueError(\n",
    "        f\"Notebook currently expects raw_input_dim={len(SURFACE_FEATURE_COLUMNS)}, got {model.hparams.raw_input_dim}.\"\n",
    "    )\n"
   ],
   "id": "3132220c60361795",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "print(\"Loading and preprocessing raw data...\")\nraw_df = load_preprocessed_surface_frame(DATA_DIR, cp_flag=CP_FLAG)\nif raw_df.is_empty():\n    raise ValueError(\"No rows remain after preprocessing.\")\n\nif SELECTED_DATE:\n    target_date = pl.Series([SELECTED_DATE]).str.strptime(pl.Date, strict=False).item()\n    if target_date is None:\n        raise ValueError(f\"Invalid SELECTED_DATE format: {SELECTED_DATE}\")\nelse:\n    target_date = raw_df.select(pl.col(\"date\").max()).item()\n\ndaily = raw_df.filter(pl.col(\"date\") == target_date)\n\nif daily.is_empty():\n    available = [\n        str(value)\n        for value in raw_df.select(pl.col(\"date\").unique().sort().tail(10)).to_series().to_list()\n    ]\n    raise ValueError(\n        f\"No rows found for SELECTED_DATE={target_date}. Last available dates: {available}\"\n    )\n\nprint(f\"Using date={target_date} with {daily.height:,} rows\")\n\n(\n    query_x,\n    context_x,\n    context_y,\n    context_mask,\n    m_grid,\n    t_grid,\n    k_grid,\n) = build_context_and_query_for_date(\n    daily_df=daily,\n    context_size=CONTEXT_SIZE,\n    grid_size=GRID_SIZE,\n    seed=SEED,\n)\n\nquery_x = query_x.to(device)\ncontext_x = context_x.to(device)\ncontext_y = context_y.to(device)\ncontext_mask = context_mask.to(device)\n\nprint(\"Predicting transformer surface...\")\nwith torch.no_grad():\n    preds_norm, greeks = model(\n        query_x=query_x,\n        context_x=context_x,\n        context_y=context_y,\n        context_mask=context_mask,\n    )\n\nk_query = query_x[:, :, 1:2]\npred_prices = (preds_norm * k_query).squeeze(0).squeeze(-1).detach().cpu().numpy()\nprice_grid = pred_prices.reshape(m_grid.shape)\n\ngreek_grids = {\n    name: tensor.squeeze(0).squeeze(-1).detach().cpu().numpy().reshape(m_grid.shape)\n    for name, tensor in greeks.items()\n}\n\nt_days_grid = t_grid * 365.0\n\nplot_surface(\n    z_grid=price_grid,\n    x_grid=m_grid,\n    y_grid=t_days_grid,\n    title=\"Predicted Call Price Surface (Transformer)\",\n    x_title=\"Moneyness (S/K)\",\n    y_title=\"Maturity (Days)\",\n    z_title=\"Price\",\n)\n\nfor greek_name in [\"delta\", \"gamma\", \"theta\", \"vega\"]:\n    plot_surface(\n        z_grid=greek_grids[greek_name],\n        x_grid=m_grid,\n        y_grid=t_days_grid,\n        title=f\"{greek_name.capitalize()} Surface (Transformer)\",\n        x_title=\"Moneyness (S/K)\",\n        y_title=\"Maturity (Days)\",\n        z_title=greek_name,\n    )\n",
   "id": "d430087e10fdc9a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"Collecting validation/testing price and Greek errors...\")\n",
    "\n",
    "import torchmetrics.functional as tmf\n",
    "from scipy.optimize import brentq\n",
    "from scipy.stats import norm\n",
    "\n",
    "MONEYNESS_BINS = [0.0, 0.5, 0.90, 0.95, 1.05, 1.10, 1.15]\n",
    "MONEYNESS_LABELS = [\n",
    "    \"DDOTM (0.00-0.50)\",\n",
    "    \"DOTM (0.50-0.90)\",\n",
    "    \"OTM (0.90-0.95)\",\n",
    "    \"ATM (0.95-1.05)\",\n",
    "    \"ITM (1.05-1.10)\",\n",
    "    \"DITM (1.10-1.15)\",\n",
    "]\n",
    "GREEK_NAMES = [\"delta\", \"gamma\", \"theta\", \"vega\"]\n",
    "\n",
    "\n",
    "def compute_torchmetrics(real_values, model_values):\n",
    "    real_values = np.asarray(real_values, dtype=np.float64)\n",
    "    model_values = np.asarray(model_values, dtype=np.float64)\n",
    "    finite = np.isfinite(real_values) & np.isfinite(model_values)\n",
    "\n",
    "    if finite.sum() == 0:\n",
    "        return {\n",
    "            \"mae\": np.nan,\n",
    "            \"mse\": np.nan,\n",
    "            \"rmse\": np.nan,\n",
    "            \"mape_pct\": np.nan,\n",
    "            \"smape_pct\": np.nan,\n",
    "            \"r2\": np.nan,\n",
    "        }\n",
    "\n",
    "    target = torch.tensor(real_values[finite], dtype=torch.float32)\n",
    "    preds = torch.tensor(model_values[finite], dtype=torch.float32)\n",
    "\n",
    "    mse = float(tmf.mean_squared_error(preds, target).item())\n",
    "\n",
    "    metrics = {\n",
    "        \"mae\": float(tmf.mean_absolute_error(preds, target).item()),\n",
    "        \"mse\": mse,\n",
    "        \"rmse\": float(np.sqrt(mse)),\n",
    "        \"mape_pct\": float(tmf.mean_absolute_percentage_error(preds, target).item() * 100.0),\n",
    "        \"smape_pct\": float(tmf.symmetric_mean_absolute_percentage_error(preds, target).item() * 100.0),\n",
    "        \"p95_abs\": float(torch.quantile(torch.abs(preds - target), 0.95)),\n",
    "        \"p90_abs\": float(torch.quantile(torch.abs(preds - target), 0.90)),\n",
    "        \"median_abs\": float(torch.quantile(torch.abs(preds - target), 0.5)),\n",
    "        \"r2\": float(tmf.r2_score(preds, target).item()) if target.numel() > 1 else np.nan,\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def summarize_errors(split_df, split_name):\n",
    "    real_values = split_df.get_column(\"real_price\").to_numpy()\n",
    "    model_values = split_df.get_column(\"model_price\").to_numpy()\n",
    "\n",
    "    metrics = compute_torchmetrics(real_values, model_values)\n",
    "    errors = split_df.get_column(\"error\").to_numpy()\n",
    "\n",
    "    print(\n",
    "        f\"{split_name}: n={len(errors):,}, mean={np.nanmean(errors):.4f}, std={np.nanstd(errors):.4f}, \"\n",
    "        f\"MAE={metrics['mae']:.4f}, RMSE={metrics['rmse']:.4f}, \"\n",
    "        f\"MAPE={metrics['mape_pct']:.2f}%, SMAPE={metrics['smape_pct']:.2f}%, R2={metrics['r2']:.4f}\"\n",
    "    )\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def bs_call_price(s, k, t, r, q, sigma):\n",
    "    if not np.isfinite([s, k, t, r, q, sigma]).all():\n",
    "        return np.nan\n",
    "    if s <= 0 or k <= 0 or t <= 0 or sigma <= 0:\n",
    "        return np.nan\n",
    "\n",
    "    sqrt_t = np.sqrt(t)\n",
    "    d1 = (np.log(s / k) + (r - q + 0.5 * sigma**2) * t) / (sigma * sqrt_t)\n",
    "    d2 = d1 - sigma * sqrt_t\n",
    "    return s * np.exp(-q * t) * norm.cdf(d1) - k * np.exp(-r * t) * norm.cdf(d2)\n",
    "\n",
    "\n",
    "def bs_call_greeks(s, k, t, r, q, sigma):\n",
    "    if not np.isfinite([s, k, t, r, q, sigma]).all():\n",
    "        return np.nan, np.nan, np.nan, np.nan\n",
    "    if s <= 0 or k <= 0 or t <= 0 or sigma <= 0:\n",
    "        return np.nan, np.nan, np.nan, np.nan\n",
    "\n",
    "    sqrt_t = np.sqrt(t)\n",
    "    d1 = (np.log(s / k) + (r - q + 0.5 * sigma**2) * t) / (sigma * sqrt_t)\n",
    "    d2 = d1 - sigma * sqrt_t\n",
    "\n",
    "    pdf_d1 = norm.pdf(d1)\n",
    "    cdf_d1 = norm.cdf(d1)\n",
    "    cdf_d2 = norm.cdf(d2)\n",
    "\n",
    "    delta = np.exp(-q * t) * cdf_d1\n",
    "    gamma = (np.exp(-q * t) * pdf_d1) / (s * sigma * sqrt_t)\n",
    "    theta = (\n",
    "        -(s * np.exp(-q * t) * pdf_d1 * sigma) / (2.0 * sqrt_t)\n",
    "        - r * k * np.exp(-r * t) * cdf_d2\n",
    "        + q * s * np.exp(-q * t) * cdf_d1\n",
    "    )\n",
    "    vega = s * np.exp(-q * t) * pdf_d1 * sqrt_t\n",
    "    return delta, gamma, theta, vega\n",
    "\n",
    "\n",
    "def implied_vol_call_from_price(price, s, k, t, r, q, sigma_min=1e-6, sigma_max=5.0):\n",
    "    if not np.isfinite([price, s, k, t, r, q]).all():\n",
    "        return np.nan\n",
    "    if s <= 0 or k <= 0 or t <= 0:\n",
    "        return np.nan\n",
    "\n",
    "    disc_q = np.exp(-q * t)\n",
    "    disc_r = np.exp(-r * t)\n",
    "    lower_bound = max(s * disc_q - k * disc_r, 0.0)\n",
    "    upper_bound = s * disc_q\n",
    "\n",
    "    # Clip observed market prices into no-arbitrage bounds to keep IV/Greek estimation stable.\n",
    "    target = float(np.clip(price, lower_bound, upper_bound))\n",
    "\n",
    "    def objective(sig):\n",
    "        return bs_call_price(s, k, t, r, q, sig) - target\n",
    "\n",
    "    f_low = objective(sigma_min)\n",
    "    f_high = objective(sigma_max)\n",
    "\n",
    "    if not np.isfinite(f_low) or not np.isfinite(f_high):\n",
    "        return np.nan\n",
    "    if abs(f_low) < 1e-10:\n",
    "        return float(sigma_min)\n",
    "    if abs(f_high) < 1e-10:\n",
    "        return float(sigma_max)\n",
    "    if f_low * f_high > 0:\n",
    "        return np.nan\n",
    "\n",
    "    try:\n",
    "        return float(brentq(objective, sigma_min, sigma_max, xtol=1e-8, rtol=1e-8, maxiter=200))\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def compute_bs_iv_and_greeks(real_prices, s_values, k_values, t_values, r_values, q_values):\n",
    "    n = len(real_prices)\n",
    "    implied_vol = np.full(n, np.nan, dtype=np.float64)\n",
    "    bs_delta = np.full(n, np.nan, dtype=np.float64)\n",
    "    bs_gamma = np.full(n, np.nan, dtype=np.float64)\n",
    "    bs_theta = np.full(n, np.nan, dtype=np.float64)\n",
    "    bs_vega = np.full(n, np.nan, dtype=np.float64)\n",
    "\n",
    "    for i in range(n):\n",
    "        sigma = implied_vol_call_from_price(\n",
    "            price=real_prices[i],\n",
    "            s=s_values[i],\n",
    "            k=k_values[i],\n",
    "            t=t_values[i],\n",
    "            r=r_values[i],\n",
    "            q=q_values[i],\n",
    "        )\n",
    "        implied_vol[i] = sigma\n",
    "\n",
    "        if np.isfinite(sigma):\n",
    "            delta, gamma, theta, vega = bs_call_greeks(\n",
    "                s=s_values[i],\n",
    "                k=k_values[i],\n",
    "                t=t_values[i],\n",
    "                r=r_values[i],\n",
    "                q=q_values[i],\n",
    "                sigma=sigma,\n",
    "            )\n",
    "            bs_delta[i] = delta\n",
    "            bs_gamma[i] = gamma\n",
    "            bs_theta[i] = theta\n",
    "            bs_vega[i] = vega\n",
    "\n",
    "    bs_greeks = {\n",
    "        \"delta\": bs_delta,\n",
    "        \"gamma\": bs_gamma,\n",
    "        \"theta\": bs_theta,\n",
    "        \"vega\": bs_vega,\n",
    "    }\n",
    "    return implied_vol, bs_greeks\n",
    "\n",
    "\n",
    "def summarize_greek_errors(split_df, split_name):\n",
    "    rows = []\n",
    "    iv_values = split_df.get_column(\"implied_vol_real\").to_numpy()\n",
    "    iv_valid = int(np.isfinite(iv_values).sum())\n",
    "    iv_pct = (100.0 * iv_valid / split_df.height) if split_df.height else 0.0\n",
    "\n",
    "    print(f\"{split_name}: implied-vol solved for {iv_valid:,}/{split_df.height:,} rows ({iv_pct:.2f}%)\")\n",
    "\n",
    "    for greek in GREEK_NAMES:\n",
    "        actual_col = f\"bs_{greek}\"\n",
    "        pred_col = f\"model_{greek}\"\n",
    "\n",
    "        actual = split_df.get_column(actual_col).to_numpy().astype(np.float64)\n",
    "        pred = split_df.get_column(pred_col).to_numpy().astype(np.float64)\n",
    "        finite = np.isfinite(actual) & np.isfinite(pred)\n",
    "\n",
    "        metrics = compute_torchmetrics(actual[finite], pred[finite]) if finite.any() else {\n",
    "            \"mae\": np.nan,\n",
    "            \"mse\": np.nan,\n",
    "            \"rmse\": np.nan,\n",
    "            \"mape_pct\": np.nan,\n",
    "            \"smape_pct\": np.nan,\n",
    "            \"r2\": np.nan,\n",
    "        }\n",
    "\n",
    "        rows.append(\n",
    "            {\n",
    "                \"split\": split_name,\n",
    "                \"greek\": greek,\n",
    "                \"n_valid\": int(finite.sum()),\n",
    "                \"mean_error\": float(np.nanmean((pred - actual)[finite])) if finite.any() else np.nan,\n",
    "                \"std_error\": float(np.nanstd((pred - actual)[finite])) if finite.any() else np.nan,\n",
    "                **metrics,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    table = pl.DataFrame(rows)\n",
    "    print(table)\n",
    "    return table\n",
    "\n",
    "\n",
    "def assign_moneyness_bucket(values):\n",
    "    values = np.asarray(values, dtype=np.float64)\n",
    "    buckets = np.array([None] * values.shape[0], dtype=object)\n",
    "\n",
    "    for idx, label in enumerate(MONEYNESS_LABELS):\n",
    "        lower = MONEYNESS_BINS[idx]\n",
    "        upper = MONEYNESS_BINS[idx + 1]\n",
    "        if idx == 0:\n",
    "            mask = (values >= lower) & (values <= upper)\n",
    "        else:\n",
    "            mask = (values > lower) & (values <= upper)\n",
    "        buckets[mask] = label\n",
    "\n",
    "    return buckets\n",
    "\n",
    "\n",
    "def load_split_quote_groups(data_dir, split_name, cp_flag=\"C\"):\n",
    "    csv_files = f\"{data_dir}/*.csv\"\n",
    "    if not glob.glob(csv_files):\n",
    "        raise ValueError(f\"No csv files found in folder {data_dir}.\")\n",
    "\n",
    "    lf = pl.scan_csv(csv_files, try_parse_dates=True)\n",
    "    schema = getattr(lf, \"collect_schema\", lambda: lf.schema)()\n",
    "\n",
    "    if schema[\"date\"] == pl.String:\n",
    "        lf = lf.with_columns(pl.col(\"date\").str.to_datetime(strict=False))\n",
    "\n",
    "    if cp_flag is not None and \"cp_flag\" in schema:\n",
    "        lf = lf.filter(pl.col(\"cp_flag\") == cp_flag)\n",
    "\n",
    "    lf = (\n",
    "        lf.filter((pl.col(\"T\") < 365) & (pl.col(\"T\") > 14))\n",
    "        .with_columns(\n",
    "            M=pl.col(\"S\") / pl.col(\"K\"),\n",
    "            vix=pl.col(\"vix\") / 100.0,\n",
    "            T=pl.col(\"T\") / 365.0,\n",
    "        )\n",
    "        .filter((pl.col(\"M\") >= 0.7) & (pl.col(\"M\") <= 1.15))\n",
    "    )\n",
    "\n",
    "    base_required = [\"date\", \"Price\", \"S\", \"K\", \"T\", \"vix\", \"dividend_yield\", \"rate\", \"delta\", \"gamma\", \"theta\"]\n",
    "    lf = lf.drop_nulls(subset=base_required)\n",
    "\n",
    "    if \"Bid\" not in schema or \"Ask\" not in schema:\n",
    "        raise ValueError(\"Bid/Ask columns are required in source CSV files for spread-based metrics.\")\n",
    "\n",
    "    final_df = lf.collect().sort(\"date\")\n",
    "    train_dates, test_dates = SurfaceOptionsDataModule._compute_date_splits(final_df)\n",
    "\n",
    "    if split_name.lower() == \"testing\":\n",
    "        selected_dates = test_dates\n",
    "    elif split_name.lower() == \"training\":\n",
    "        selected_dates = train_dates\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported split_name={split_name}. Expected 'Testing' or 'Training'.\")\n",
    "\n",
    "    split_df = final_df.filter(pl.col(\"date\").dt.date().is_in(selected_dates)).with_columns(\n",
    "        date_only=pl.col(\"date\").dt.date()\n",
    "    )\n",
    "\n",
    "    groups = []\n",
    "    for date_key, group in split_df.group_by(\"date_only\", maintain_order=True):\n",
    "        date_value = date_key[0] if isinstance(date_key, tuple) else date_key\n",
    "        groups.append((date_value, group))\n",
    "\n",
    "    return groups\n",
    "\n",
    "\n",
    "def collect_error_frame(loader, split_name, split_dataset=None, split_quote_groups=None):\n",
    "    moneyness_parts = []\n",
    "    s_parts = []\n",
    "    k_parts = []\n",
    "    t_years_parts = []\n",
    "    t_days_parts = []\n",
    "    dividend_parts = []\n",
    "    rate_parts = []\n",
    "\n",
    "    real_prices = []\n",
    "    model_prices = []\n",
    "    model_greek_parts = {name: [] for name in GREEK_NAMES}\n",
    "\n",
    "    quote_enabled = split_dataset is not None and split_quote_groups is not None\n",
    "    if quote_enabled and len(split_quote_groups) != len(split_dataset):\n",
    "        raise ValueError(\n",
    "            f\"split_quote_groups length ({len(split_quote_groups)}) must match dataset length ({len(split_dataset)}).\"\n",
    "        )\n",
    "\n",
    "    bid_parts = []\n",
    "    ask_parts = []\n",
    "    mid_parts = []\n",
    "    spread_parts = []\n",
    "    quote_valid_parts = []\n",
    "    within_half_parts = []\n",
    "    within_one_parts = []\n",
    "    abs_pred_mid_parts = []\n",
    "\n",
    "    dataset_item_offset = 0\n",
    "\n",
    "    for batch in loader:\n",
    "        query_x = batch[\"query_x\"].to(device)\n",
    "        query_y = batch[\"query_y\"].to(device)\n",
    "        query_mask = batch[\"query_mask\"].to(device)\n",
    "        context_x = batch[\"context_x\"].to(device)\n",
    "        context_y = batch[\"context_y\"].to(device)\n",
    "        context_mask = batch[\"context_mask\"].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            preds_norm, greeks = model(\n",
    "                query_x=query_x,\n",
    "                context_x=context_x,\n",
    "                context_y=context_y,\n",
    "                context_mask=context_mask,\n",
    "            )\n",
    "\n",
    "        s = query_x[:, :, 0:1]\n",
    "        k = query_x[:, :, 1:2]\n",
    "        t_years = query_x[:, :, 2:3]\n",
    "        t_days = t_years * 365.0\n",
    "        dividend = query_x[:, :, 4:5]\n",
    "        rate = query_x[:, :, 5:6]\n",
    "        model_price_tensor = preds_norm * k\n",
    "\n",
    "        query_mask_np = query_mask.detach().cpu().numpy().astype(bool)\n",
    "\n",
    "        for sample_idx in range(query_x.shape[0]):\n",
    "            sample_valid_mask = query_mask_np[sample_idx].reshape(-1)\n",
    "            if not sample_valid_mask.any():\n",
    "                continue\n",
    "\n",
    "            sample_model_prices = model_price_tensor[sample_idx].detach().cpu().numpy().reshape(-1)[sample_valid_mask]\n",
    "            sample_real_prices = query_y[sample_idx].detach().cpu().numpy().reshape(-1)[sample_valid_mask]\n",
    "\n",
    "            model_prices.append(sample_model_prices)\n",
    "            real_prices.append(sample_real_prices)\n",
    "\n",
    "            sample_s = s[sample_idx].detach().cpu().numpy().reshape(-1)[sample_valid_mask]\n",
    "            sample_k = k[sample_idx].detach().cpu().numpy().reshape(-1)[sample_valid_mask]\n",
    "\n",
    "            s_parts.append(sample_s)\n",
    "            k_parts.append(sample_k)\n",
    "            t_years_parts.append(t_years[sample_idx].detach().cpu().numpy().reshape(-1)[sample_valid_mask])\n",
    "            t_days_parts.append(t_days[sample_idx].detach().cpu().numpy().reshape(-1)[sample_valid_mask])\n",
    "            dividend_parts.append(dividend[sample_idx].detach().cpu().numpy().reshape(-1)[sample_valid_mask])\n",
    "            rate_parts.append(rate[sample_idx].detach().cpu().numpy().reshape(-1)[sample_valid_mask])\n",
    "            moneyness_parts.append(sample_s / np.clip(sample_k, 1e-8, None))\n",
    "\n",
    "            for greek in GREEK_NAMES:\n",
    "                model_greek_parts[greek].append(\n",
    "                    greeks[greek][sample_idx].detach().cpu().numpy().reshape(-1)[sample_valid_mask]\n",
    "                )\n",
    "\n",
    "            if quote_enabled:\n",
    "                item_idx = dataset_item_offset + sample_idx\n",
    "                _, source_group = split_quote_groups[item_idx]\n",
    "                row_count = source_group.height\n",
    "\n",
    "                rng = split_dataset._make_rng(item_idx)\n",
    "                _, query_idx = split_dataset._select_context_query_indices(row_count, rng)\n",
    "                query_idx_np = query_idx.detach().cpu().numpy().astype(np.int64)\n",
    "\n",
    "                if query_idx_np.shape[0] != sample_model_prices.shape[0]:\n",
    "                    raise ValueError(\n",
    "                        \"Quote alignment mismatch: deterministic query index count does not match valid query mask count.\"\n",
    "                    )\n",
    "\n",
    "                source_rows = source_group[query_idx_np.tolist()]\n",
    "                bid_vals = source_rows.get_column(\"Bid\").to_numpy().astype(np.float64)\n",
    "                ask_vals = source_rows.get_column(\"Ask\").to_numpy().astype(np.float64)\n",
    "\n",
    "                mid_vals = 0.5 * (bid_vals + ask_vals)\n",
    "                spread_vals = ask_vals - bid_vals\n",
    "                valid_quotes = (\n",
    "                    np.isfinite(bid_vals)\n",
    "                    & np.isfinite(ask_vals)\n",
    "                    & np.isfinite(spread_vals)\n",
    "                    & (spread_vals >= 0.0)\n",
    "                )\n",
    "\n",
    "                sample_abs_pred_mid = np.abs(sample_model_prices.astype(np.float64) - mid_vals)\n",
    "                within_half = np.where(valid_quotes, sample_abs_pred_mid <= (0.5 * spread_vals), False)\n",
    "                within_one = np.where(valid_quotes, sample_abs_pred_mid <= spread_vals, False)\n",
    "\n",
    "                bid_parts.append(bid_vals)\n",
    "                ask_parts.append(ask_vals)\n",
    "                mid_parts.append(mid_vals)\n",
    "                spread_parts.append(spread_vals)\n",
    "                quote_valid_parts.append(valid_quotes)\n",
    "                within_half_parts.append(within_half)\n",
    "                within_one_parts.append(within_one)\n",
    "                abs_pred_mid_parts.append(sample_abs_pred_mid)\n",
    "\n",
    "        dataset_item_offset += int(query_x.shape[0])\n",
    "\n",
    "    if not real_prices:\n",
    "        raise ValueError(f\"No rows available for {split_name} set.\")\n",
    "\n",
    "    real_prices = np.concatenate(real_prices)\n",
    "    model_prices = np.concatenate(model_prices)\n",
    "\n",
    "    s_values = np.concatenate(s_parts)\n",
    "    k_values = np.concatenate(k_parts)\n",
    "    t_years_values = np.concatenate(t_years_parts)\n",
    "    t_days_values = np.concatenate(t_days_parts)\n",
    "    dividend_values = np.concatenate(dividend_parts)\n",
    "    rate_values = np.concatenate(rate_parts)\n",
    "    moneyness = np.concatenate(moneyness_parts)\n",
    "\n",
    "    r_values = np.where(np.isfinite(rate_values), rate_values, 0.0)\n",
    "    q_values = np.where(np.isfinite(dividend_values), dividend_values, 0.0)\n",
    "\n",
    "    implied_vol_real, bs_greeks = compute_bs_iv_and_greeks(\n",
    "        real_prices=real_prices,\n",
    "        s_values=s_values,\n",
    "        k_values=k_values,\n",
    "        t_values=t_years_values,\n",
    "        r_values=r_values,\n",
    "        q_values=q_values,\n",
    "    )\n",
    "\n",
    "    model_greeks = {\n",
    "        greek: np.concatenate(parts) if parts else np.array([], dtype=np.float64)\n",
    "        for greek, parts in model_greek_parts.items()\n",
    "    }\n",
    "\n",
    "    abs_error = np.abs(model_prices - real_prices)\n",
    "    abs_pct_error = np.where(np.abs(real_prices) > 1e-8, (abs_error / np.abs(real_prices)) * 100.0, np.nan)\n",
    "\n",
    "    frame = pl.DataFrame(\n",
    "        {\n",
    "            \"split\": split_name,\n",
    "            \"S\": s_values,\n",
    "            \"K\": k_values,\n",
    "            \"T_years\": t_years_values,\n",
    "            \"T_days\": t_days_values,\n",
    "            \"moneyness\": moneyness,\n",
    "            \"risk_free_rate\": r_values,\n",
    "            \"dividend_yield\": q_values,\n",
    "            \"real_price\": real_prices,\n",
    "            \"model_price\": model_prices,\n",
    "            \"error\": model_prices - real_prices,\n",
    "            \"abs_error\": abs_error,\n",
    "            \"abs_pct_error\": abs_pct_error,\n",
    "            \"difference\": real_prices - model_prices,\n",
    "            \"implied_vol_real\": implied_vol_real,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    if quote_enabled:\n",
    "        bid_values = np.concatenate(bid_parts)\n",
    "        ask_values = np.concatenate(ask_parts)\n",
    "        mid_values = np.concatenate(mid_parts)\n",
    "        spread_values = np.concatenate(spread_parts)\n",
    "        quote_valid_values = np.concatenate(quote_valid_parts)\n",
    "        within_half_values = np.concatenate(within_half_parts)\n",
    "        within_one_values = np.concatenate(within_one_parts)\n",
    "        abs_pred_mid_values = np.concatenate(abs_pred_mid_parts)\n",
    "\n",
    "        if bid_values.shape[0] != frame.height:\n",
    "            raise ValueError(\n",
    "                f\"Quote metric length mismatch: got {bid_values.shape[0]} rows for quotes and {frame.height} model rows.\"\n",
    "            )\n",
    "\n",
    "        frame = frame.with_columns(\n",
    "            [\n",
    "                pl.Series(name=\"bid_price\", values=bid_values),\n",
    "                pl.Series(name=\"ask_price\", values=ask_values),\n",
    "                pl.Series(name=\"mid_price\", values=mid_values),\n",
    "                pl.Series(name=\"spread\", values=spread_values),\n",
    "                pl.Series(name=\"quote_valid\", values=quote_valid_values),\n",
    "                pl.Series(name=\"abs_pred_minus_mid\", values=abs_pred_mid_values),\n",
    "                pl.Series(name=\"within_0_5_spread\", values=within_half_values),\n",
    "                pl.Series(name=\"within_1_0_spread\", values=within_one_values),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    extra_cols = []\n",
    "    for greek in GREEK_NAMES:\n",
    "        extra_cols.append(pl.Series(name=f\"model_{greek}\", values=model_greeks[greek]))\n",
    "        extra_cols.append(pl.Series(name=f\"bs_{greek}\", values=bs_greeks[greek]))\n",
    "    frame = frame.with_columns(extra_cols)\n",
    "\n",
    "    frame = frame.with_columns(\n",
    "        [\n",
    "            (pl.col(f\"model_{greek}\") - pl.col(f\"bs_{greek}\")).alias(f\"{greek}_error\")\n",
    "            for greek in GREEK_NAMES\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    frame = frame.with_columns(\n",
    "        pl.Series(name=\"moneyness_bucket\", values=assign_moneyness_bucket(moneyness))\n",
    "    )\n",
    "\n",
    "    split_metrics = summarize_errors(frame, split_name)\n",
    "    greek_metrics = summarize_greek_errors(frame, split_name)\n",
    "    return frame, split_metrics, greek_metrics\n",
    "\n",
    "\n",
    "test_quote_groups = load_split_quote_groups(DATA_DIR, split_name=\"Testing\", cp_flag=CP_FLAG)\n",
    "\n",
    "test_df, test_metrics, test_greek_metrics = collect_error_frame(\n",
    "    data_module.test_dataloader(),\n",
    "    \"Testing\",\n",
    "    split_dataset=data_module.test,\n",
    "    split_quote_groups=test_quote_groups,\n",
    ")\n",
    "all_errors = pl.concat([test_df], how=\"vertical_relaxed\")\n",
    "\n",
    "overall_metrics = compute_torchmetrics(\n",
    "\n",
    "    all_errors.get_column(\"real_price\").to_numpy(),\n",
    "    all_errors.get_column(\"model_price\").to_numpy(),\n",
    ")\n",
    "\n",
    "metrics_table = pl.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"split\": \"Testing\",\n",
    "            \"n\": test_df.height,\n",
    "            **test_metrics,\n",
    "        },\n",
    "        {\n",
    "            \"split\": \"Combined\",\n",
    "            \"n\": all_errors.height,\n",
    "            **overall_metrics,\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "print()\n",
    "print(\"Torchmetrics summary (prices):\")\n",
    "metrics_table.show()\n",
    "\n",
    "combined_greek_rows = []\n",
    "for greek in GREEK_NAMES:\n",
    "    actual = all_errors.get_column(f\"bs_{greek}\").to_numpy().astype(np.float64)\n",
    "    pred = all_errors.get_column(f\"model_{greek}\").to_numpy().astype(np.float64)\n",
    "    finite = np.isfinite(actual) & np.isfinite(pred)\n",
    "    metrics = compute_torchmetrics(actual[finite], pred[finite]) if finite.any() else {\n",
    "        \"mae\": np.nan,\n",
    "        \"mse\": np.nan,\n",
    "        \"rmse\": np.nan,\n",
    "        \"mape_pct\": np.nan,\n",
    "        \"smape_pct\": np.nan,\n",
    "        \"r2\": np.nan,\n",
    "    }\n",
    "    combined_greek_rows.append(\n",
    "        {\n",
    "            \"split\": \"Combined\",\n",
    "            \"greek\": greek,\n",
    "            \"n_valid\": int(finite.sum()),\n",
    "            \"mean_error\": float(np.nanmean((pred - actual)[finite])) if finite.any() else np.nan,\n",
    "            \"std_error\": float(np.nanstd((pred - actual)[finite])) if finite.any() else np.nan,\n",
    "            **metrics,\n",
    "        }\n",
    "    )\n",
    "\n",
    "combined_greek_metrics = pl.DataFrame(combined_greek_rows)\n",
    "greek_metrics_table = pl.concat(\n",
    "    [test_greek_metrics, combined_greek_metrics],\n",
    "    how=\"vertical_relaxed\",\n",
    ")\n",
    "\n",
    "print()\n",
    "print(\"Torchmetrics summary (Greeks vs Black-Scholes Greeks from real implied vol):\")\n",
    "greek_metrics_table.show()\n",
    "\n",
    "surface_df = all_errors.select([\"split\", \"K\", \"T_days\", \"difference\", \"moneyness\"]).with_columns(\n",
    "    pl.col(\"T_days\").round(0).alias(\"T_days\"),\n",
    "    pl.col(\"moneyness\").round(3).alias(\"moneyness\"),\n",
    ")\n",
    "\n",
    "bucket_rows = []\n",
    "for split_name, split_df in [(\"Testing\", test_df)]:\n",
    "    for bucket in MONEYNESS_LABELS:\n",
    "        bucket_df = split_df.filter(pl.col(\"moneyness_bucket\") == bucket)\n",
    "        if bucket_df.is_empty():\n",
    "            continue\n",
    "\n",
    "        bucket_tm = compute_torchmetrics(\n",
    "            bucket_df.get_column(\"real_price\").to_numpy(),\n",
    "            bucket_df.get_column(\"model_price\").to_numpy(),\n",
    "        )\n",
    "\n",
    "        quote_valid_count = 0\n",
    "        pct_within_0_5_spread = np.nan\n",
    "        pct_within_1_0_spread = np.nan\n",
    "        if \"quote_valid\" in bucket_df.columns:\n",
    "            valid_quote_df = bucket_df.filter(pl.col(\"quote_valid\"))\n",
    "            quote_valid_count = valid_quote_df.height\n",
    "            if quote_valid_count > 0:\n",
    "                pct_within_0_5_spread = float(\n",
    "                    valid_quote_df.select(pl.col(\"within_0_5_spread\").cast(pl.Float64).mean()).item() * 100.0\n",
    "                )\n",
    "                pct_within_1_0_spread = float(\n",
    "                    valid_quote_df.select(pl.col(\"within_1_0_spread\").cast(pl.Float64).mean()).item() * 100.0\n",
    "                )\n",
    "\n",
    "        bucket_rows.append(\n",
    "            {\n",
    "                \"split\": split_name,\n",
    "                \"moneyness_bucket\": bucket,\n",
    "                \"n\": bucket_df.height,\n",
    "                \"n_quote_valid\": quote_valid_count,\n",
    "                \"mean_error\": float(bucket_df.select(pl.col(\"error\").mean()).item()),\n",
    "                \"std_error\": float(bucket_df.select(pl.col(\"error\").std()).item()),\n",
    "                \"mean_moneyness\": float(bucket_df.select(pl.col(\"moneyness\").mean()).item()),\n",
    "                \"pct_abs_pred_minus_mid_le_0_5_spread\": pct_within_0_5_spread,\n",
    "                \"pct_abs_pred_minus_mid_le_1_0_spread\": pct_within_1_0_spread,\n",
    "                **bucket_tm,\n",
    "            }\n",
    "        )\n",
    "\n",
    "bucket_metrics = pl.DataFrame(bucket_rows)\n",
    "print()\n",
    "print(\"Error metrics by moneyness bucket (prices + spread-relative coverage):\")\n",
    "bucket_metrics.show()\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=test_df.get_column(\"error\").to_numpy(),\n",
    "        name=\"Testing Error\",\n",
    "        opacity=0.65,\n",
    "        histnorm=\"percent\",\n",
    "        nbinsx=80,\n",
    "        marker_color=\"#ff7f0e\",\n",
    "    )\n",
    ")\n",
    "fig.add_vline(x=0.0, line_dash=\"dash\", line_color=\"black\")\n",
    "fig.update_layout(\n",
    "    title=\"Error Distribution: Model Price - Real Price (Validation vs Testing)\",\n",
    "    xaxis_title=\"Pricing Error\",\n",
    "    yaxis_title=\"Percent of Samples (%)\",\n",
    "    barmode=\"overlay\",\n",
    "    template=\"plotly_white\",\n",
    "    width=1000,\n",
    "    height=500,\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "if not bucket_metrics.is_empty():\n",
    "    mae_fig = go.Figure()\n",
    "    for split_name, color in [(\"Validation\", \"#1f77b4\"), (\"Testing\", \"#ff7f0e\")]:\n",
    "        split_metrics = bucket_metrics.filter(pl.col(\"split\") == split_name)\n",
    "        if split_metrics.is_empty():\n",
    "            continue\n",
    "        mae_fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=split_metrics.get_column(\"moneyness_bucket\").to_list(),\n",
    "                y=split_metrics.get_column(\"mae\").to_numpy(),\n",
    "                name=f\"{split_name} MAE\",\n",
    "                marker_color=color,\n",
    "                opacity=0.85,\n",
    "            )\n",
    "        )\n",
    "    mae_fig.update_layout(\n",
    "        title=\"MAE by Moneyness Bucket\",\n",
    "        xaxis_title=\"Moneyness Bucket\",\n",
    "        yaxis_title=\"MAE\",\n",
    "        barmode=\"group\",\n",
    "        template=\"plotly_white\",\n",
    "        width=1000,\n",
    "        height=450,\n",
    "    )\n",
    "    mae_fig.show()\n",
    "\n",
    "SCATTER_BUCKET_EDGES = [0.0, 0.97, 1.03, 1.10, np.inf]\n",
    "SCATTER_BUCKET_LABELS = [\n",
    "    \"OTM (<0.97)\",\n",
    "    \"ATM (0.97-1.03)\",\n",
    "    \"ITM (1.03-1.10)\",\n",
    "    \"Deep ITM (>=1.10)\",\n",
    "]\n",
    "SCATTER_BUCKET_KEYS = [\"otm\", \"atm\", \"itm\", \"deep_itm\"]\n",
    "\n",
    "\n",
    "def plot_bucketed_predicted_vs_actual(split_df, split_name):\n",
    "    moneyness = split_df.get_column(\"moneyness\").to_numpy()\n",
    "    actual_all = split_df.get_column(\"real_price\").to_numpy()\n",
    "    predicted_all = split_df.get_column(\"model_price\").to_numpy()\n",
    "\n",
    "    for lower, upper, label, key in zip(\n",
    "        SCATTER_BUCKET_EDGES[:-1],\n",
    "        SCATTER_BUCKET_EDGES[1:],\n",
    "        SCATTER_BUCKET_LABELS,\n",
    "        SCATTER_BUCKET_KEYS,\n",
    "    ):\n",
    "        mask = (moneyness >= lower) & (moneyness < upper)\n",
    "        if not mask.any():\n",
    "            continue\n",
    "\n",
    "        actual = actual_all[mask]\n",
    "        predicted = predicted_all[mask]\n",
    "        finite = np.isfinite(actual) & np.isfinite(predicted)\n",
    "        actual = actual[finite]\n",
    "        predicted = predicted[finite]\n",
    "\n",
    "        if actual.size == 0:\n",
    "            continue\n",
    "\n",
    "        min_val = float(min(actual.min(), predicted.min()))\n",
    "        max_val = float(max(actual.max(), predicted.max()))\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.scatter(actual, predicted, s=5, alpha=0.5)\n",
    "        plt.plot([min_val, max_val], [min_val, max_val], \"r--\")\n",
    "        plt.xlabel(\"Actual Price\")\n",
    "        plt.ylabel(\"Predicted Price\")\n",
    "        plt.title(f\"Predicted vs Actual Option Prices - {label} ({split_name})\")\n",
    "        plt.tight_layout()\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "for split_name, split_df in [(\"Testing\", test_df)]:\n",
    "    plot_bucketed_predicted_vs_actual(split_df, split_name)\n"
   ],
   "id": "198515037cd913f8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "bucket_metrics",
   "id": "c94a39972b671b29",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if \"all_errors\" not in globals():\n",
    "    raise ValueError(\"all_errors is missing. Run the error collection cell first.\")\n",
    "if all_errors.is_empty():\n",
    "    raise ValueError(\"all_errors is empty. Run the error collection cell first.\")\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "if \"GREEK_NAMES\" not in globals():\n",
    "    GREEK_NAMES = [\"delta\", \"gamma\", \"theta\", \"vega\"]\n",
    "\n",
    "\n",
    "def pivot_surface(frame, value_col):\n",
    "    agg = (\n",
    "        frame.group_by([\"T_days\", \"moneyness\"])\n",
    "        .agg(pl.col(value_col).mean().alias(value_col))\n",
    "        .sort([\"T_days\", \"moneyness\"])\n",
    "    )\n",
    "\n",
    "    if agg.is_empty():\n",
    "        return None, None, None\n",
    "\n",
    "    t_values = np.sort(agg.get_column(\"T_days\").unique().to_numpy())\n",
    "    m_values = np.sort(agg.get_column(\"moneyness\").unique().to_numpy())\n",
    "    z_grid = np.full((len(t_values), len(m_values)), np.nan, dtype=np.float64)\n",
    "\n",
    "    t_index = {float(value): idx for idx, value in enumerate(t_values.tolist())}\n",
    "    m_index = {float(value): idx for idx, value in enumerate(m_values.tolist())}\n",
    "\n",
    "    for t_val, m_val, z_val in zip(\n",
    "        agg.get_column(\"T_days\").to_numpy(),\n",
    "        agg.get_column(\"moneyness\").to_numpy(),\n",
    "        agg.get_column(value_col).to_numpy(),\n",
    "    ):\n",
    "        z_grid[t_index[float(t_val)], m_index[float(m_val)]] = float(z_val)\n",
    "\n",
    "    return t_values, m_values, z_grid\n",
    "\n",
    "\n",
    "def aligned_surfaces(frame, real_col, pred_col):\n",
    "    surface_frame = frame.select([\"T_days\", \"moneyness\", real_col, pred_col]).with_columns(\n",
    "        pl.col(\"T_days\").round(0).alias(\"T_days\"),\n",
    "        pl.col(\"moneyness\").round(3).alias(\"moneyness\"),\n",
    "    )\n",
    "\n",
    "    real_t, real_m, real_surface = pivot_surface(surface_frame, real_col)\n",
    "    pred_t, pred_m, pred_surface = pivot_surface(surface_frame, pred_col)\n",
    "\n",
    "    if real_t is None or pred_t is None:\n",
    "        return None, None, None, None, None\n",
    "\n",
    "    common_t = np.intersect1d(real_t, pred_t)\n",
    "    common_m = np.intersect1d(real_m, pred_m)\n",
    "\n",
    "    if common_t.size == 0 or common_m.size == 0:\n",
    "        return None, None, None, None, None\n",
    "\n",
    "    real_t_index = {float(value): idx for idx, value in enumerate(real_t.tolist())}\n",
    "    real_m_index = {float(value): idx for idx, value in enumerate(real_m.tolist())}\n",
    "    pred_t_index = {float(value): idx for idx, value in enumerate(pred_t.tolist())}\n",
    "    pred_m_index = {float(value): idx for idx, value in enumerate(pred_m.tolist())}\n",
    "\n",
    "    real_t_pos = [real_t_index[float(value)] for value in common_t]\n",
    "    real_m_pos = [real_m_index[float(value)] for value in common_m]\n",
    "    pred_t_pos = [pred_t_index[float(value)] for value in common_t]\n",
    "    pred_m_pos = [pred_m_index[float(value)] for value in common_m]\n",
    "\n",
    "    aligned_real = real_surface[np.ix_(real_t_pos, real_m_pos)]\n",
    "    aligned_pred = pred_surface[np.ix_(pred_t_pos, pred_m_pos)]\n",
    "    error_surface = aligned_pred - aligned_real\n",
    "\n",
    "    return common_t, common_m, aligned_real, aligned_pred, error_surface\n",
    "\n",
    "\n",
    "def plot_surface_triplet(\n",
    "    t_axis,\n",
    "    m_axis,\n",
    "    real_surface,\n",
    "    pred_surface,\n",
    "    error_surface,\n",
    "    title,\n",
    "    real_title,\n",
    "    pred_title,\n",
    "    error_title,\n",
    "    z_title,\n",
    "    error_z_title,\n",
    "):\n",
    "    fig = make_subplots(\n",
    "        rows=1,\n",
    "        cols=3,\n",
    "        specs=[[{\"type\": \"surface\"}, {\"type\": \"surface\"}, {\"type\": \"surface\"}]],\n",
    "        subplot_titles=(real_title, pred_title, error_title),\n",
    "        horizontal_spacing=0.01,\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Surface(\n",
    "            z=real_surface,\n",
    "            x=m_axis,\n",
    "            y=t_axis,\n",
    "            colorscale=\"Blues\",\n",
    "            showscale=False,\n",
    "        ),\n",
    "        row=1,\n",
    "        col=1,\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Surface(\n",
    "            z=pred_surface,\n",
    "            x=m_axis,\n",
    "            y=t_axis,\n",
    "            colorscale=\"Viridis\",\n",
    "            showscale=False,\n",
    "        ),\n",
    "        row=1,\n",
    "        col=2,\n",
    "    )\n",
    "    fig.add_trace(\n",
    "        go.Surface(\n",
    "            z=error_surface,\n",
    "            x=m_axis,\n",
    "            y=t_axis,\n",
    "            colorscale=\"RdBu\",\n",
    "            colorbar=dict(title=error_z_title, x=1.01, len=0.78, thickness=10),\n",
    "            hovertemplate=\"Moneyness=%{x:.3f}<br>T(days)=%{y:.0f}<br>Error=%{z:.4f}<extra></extra>\",\n",
    "        ),\n",
    "        row=1,\n",
    "        col=3,\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        template=\"plotly_white\",\n",
    "        autosize=True,\n",
    "        height=560,\n",
    "        margin=dict(l=0, r=0, t=70, b=0),\n",
    "        scene=dict(aspectmode=\"cube\"),\n",
    "        scene2=dict(aspectmode=\"cube\"),\n",
    "        scene3=dict(aspectmode=\"cube\"),\n",
    "    )\n",
    "\n",
    "    fig.update_scenes(\n",
    "        xaxis_title_text=\"Moneyness (S/K)\",\n",
    "        yaxis_title_text=\"Maturity (days)\",\n",
    "        zaxis_title_text=z_title,\n",
    "        row=1,\n",
    "        col=1,\n",
    "    )\n",
    "    fig.update_scenes(\n",
    "        xaxis_title_text=\"Moneyness (S/K)\",\n",
    "        yaxis_title_text=\"Maturity (days)\",\n",
    "        zaxis_title_text=z_title,\n",
    "        row=1,\n",
    "        col=2,\n",
    "    )\n",
    "    fig.update_scenes(\n",
    "        xaxis_title_text=\"Moneyness (S/K)\",\n",
    "        yaxis_title_text=\"Maturity (days)\",\n",
    "        zaxis_title_text=error_z_title,\n",
    "        row=1,\n",
    "        col=3,\n",
    "    )\n",
    "\n",
    "    fig.show(config={\"responsive\": True})\n",
    "\n",
    "\n",
    "price_t, price_m, price_real, price_pred, price_error = aligned_surfaces(\n",
    "    frame=all_errors,\n",
    "    real_col=\"real_price\",\n",
    "    pred_col=\"model_price\",\n",
    ")\n",
    "\n",
    "if price_t is None:\n",
    "    raise ValueError(\"No overlapping grid points available for price surface comparison.\")\n",
    "\n",
    "plot_surface_triplet(\n",
    "    t_axis=price_t,\n",
    "    m_axis=price_m,\n",
    "    real_surface=price_real,\n",
    "    pred_surface=price_pred,\n",
    "    error_surface=price_error,\n",
    "    title=\"Option Price Surfaces: Real vs Predicted\",\n",
    "    real_title=\"Real Price Surface\",\n",
    "    pred_title=\"Predicted Price Surface\",\n",
    "    error_title=\"Price Error Surface\",\n",
    "    z_title=\"Price\",\n",
    "    error_z_title=\"Predicted - Real\",\n",
    ")\n",
    "\n",
    "greek_title_map = {\n",
    "    \"delta\": \"Delta\",\n",
    "    \"gamma\": \"Gamma\",\n",
    "    \"theta\": \"Theta\",\n",
    "    \"vega\": \"Vega\",\n",
    "}\n",
    "\n",
    "for greek in GREEK_NAMES:\n",
    "    real_col = f\"bs_{greek}\"\n",
    "    pred_col = f\"model_{greek}\"\n",
    "\n",
    "    valid_df = all_errors.select([\"T_days\", \"moneyness\", real_col, pred_col]).filter(\n",
    "        pl.col(real_col).is_finite() & pl.col(pred_col).is_finite()\n",
    "    )\n",
    "\n",
    "    if valid_df.is_empty():\n",
    "        print(f\"Skipping {greek}: no finite rows after implied-vol/Greek calculation.\")\n",
    "        continue\n",
    "\n",
    "    t_axis, m_axis, real_surface, pred_surface, error_surface = aligned_surfaces(\n",
    "        frame=valid_df,\n",
    "        real_col=real_col,\n",
    "        pred_col=pred_col,\n",
    "    )\n",
    "\n",
    "    if t_axis is None:\n",
    "        print(f\"Skipping {greek}: no overlapping grid points for surface plotting.\")\n",
    "        continue\n",
    "\n",
    "    greek_label = greek_title_map[greek]\n",
    "    plot_surface_triplet(\n",
    "        t_axis=t_axis,\n",
    "        m_axis=m_axis,\n",
    "        real_surface=real_surface,\n",
    "        pred_surface=pred_surface,\n",
    "        error_surface=error_surface,\n",
    "        title=f\"{greek_label} Surfaces: Black-Scholes (Real IV) vs Model\",\n",
    "        real_title=f\"BS {greek_label}\",\n",
    "        pred_title=f\"Model {greek_label}\",\n",
    "        error_title=f\"{greek_label} Error\",\n",
    "        z_title=greek_label,\n",
    "        error_z_title=f\"Model - BS {greek_label}\",\n",
    "    )\n"
   ],
   "id": "34ca73f08674d6c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "cdb18622dbfb6d81",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
